GloVe implementation in Zig


## Download pre-trained word vectors \*\***NEW 2024 VECTORS**\*\*
The links below contain word vectors obtained from the respective corpora. If you want word vectors trained on massive web datasets, you need only download one of these text files! Pre-trained word vectors are made available under the <a href="https://opendatacommons.org/licenses/pddl/">Public Domain Dedication and License</a>.
<div class="entry">
<ul style="padding-left:0px; margin-top:0px; margin-bottom:0px">
  <li> **NEW!!** 2024 Dolma (220B tokens, 1.2M vocab, uncased, 300d vectors, 1.6 GB download): <a href="https://nlp.stanford.edu/data/wordvecs/glove.2024.dolma.300d.zip">glove.2024.dolma.300d.zip</a> </li>
  <li> **NEW!!** 2024 Wikipedia + Gigaword 5 (11.9B tokens, 1.2M vocab, uncased, 300d vectors, 1.6 GB download): <a href="https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.300d.zip">glove.2024.wikigiga.300d.zip</a> </li>
  <li> **NEW!!** 2024 Wikipedia + Gigaword 5 (11.9B tokens, 1.2M vocab, uncased, 200d vectors, 1.1 GB download): <a href="https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.200d.zip">glove.2024.wikigiga.200d.zip</a> </li>
  <li> **NEW!!** 2024 Wikipedia + Gigaword 5 (11.9B tokens, 1.2M vocab, uncased, 100d vectors, 560 MB download): <a href="https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.100d.zip">glove.2024.wikigiga.100d.zip</a> </li>
   <li> **NEW!!** 2024 Wikipedia + Gigaword 5 (11.9B tokens, 1.2M vocab, uncased, 50d vectors, 290 MB download): <a href="https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.50d.zip">glove.2024.wikigiga.50d.zip</a> </li>
  <li> Common Crawl (42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download): <a href="https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip">glove.42B.300d.zip</a> [<a href="https://nlp.stanford.edu/data/wordvecs/glove.42B.300d.zip">mirror</a>] </li>
  <li> Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download): <a href="https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip">glove.840B.300d.zip</a> [<a href="https://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip">mirror</a>] </li>
  <li> Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d vectors, 822 MB download): <a href="https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip">glove.6B.zip</a> [<a href="https://nlp.stanford.edu/data/wordvecs/glove.6B.zip">mirror</a>] </li>
  <li> Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 200d vectors, 1.42 GB download): <a href="https://huggingface.co/stanfordnlp/glove/resolve/main/glove.twitter.27B.zip">glove.twitter.27B.zip</a> [<a href="https://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip">mirror</a>] </li>
</ul>
</div>
